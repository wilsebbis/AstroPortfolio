---
import ProjectDetailLayout from "../../layouts/ProjectDetailLayout.astro";

const metrics = [
    { label: "Dice Coeff", value: "0.92" },
    { label: "FP per Scan", value: "1.2 (vs 4.0)" },
    { label: "Sensitivity", value: "96.5%" },
    { label: "Inference", value: "150ms/slice" },
];
---

<ProjectDetailLayout
    title="Robust Semantic Segmentation for CT Scans"
    description="Automated lung nodule detection using Bayesian U-Net for uncertainty quantification and false positive reduction."
    metrics={metrics}
    github="#"
>
    <h2>Problem & Constraints</h2>
    <p>
        Radiologists miss up to 30% of small lung nodules in CT scans due to
        fatigue. While standard segmentation networks (like <code translate="no"
            >U-Net</code
        >) exist, they suffer from
        <strong>overconfidence on out-of-distribution data</strong>, leading to
        high false positive rates (flagging healthy tissue as cancer). Clinical
        adoption requires minimal false alarms (< 2 per scan) while maintaining
        95%+ sensitivity.
    </p>

    <h2>Approach</h2>
    <p>
        I developed a two-stage pipeline focusing on reliability and uncertainty
        estimation:
    </p>
    <ul>
        <li>
            <strong><code translate="no">Bayesian U-Net</code>:</strong> Implemented
            <code translate="no">Monte Carlo Dropout</code> active during inference
            time. This allows the model to output a predictive distribution rather
            than a single value.
        </li>
        <li>
            <strong>Uncertainty Filtering:</strong> Calculated pixel-wise variance
            across 50 Monte Carlo forward passes. Regions with high variance (uncertainty)
            were automatically discarded or flagged for manual review, drastically
            reducing false positives.
        </li>
        <li>
            <strong>Data Augmentation:</strong> Applied elastic deformations and 3D
            rotations to simulate anatomical variations and handle limited labeled
            training data (<code translate="no">LUNA16</code> dataset).
        </li>
    </ul>

    <h2>Baselines & Evaluation</h2>
    <p>
        Tested on the independent <code translate="no">LUNA16</code> test set using
        strict patient-level separation (no leakage).
    </p>

    <div class="overflow-x-auto">
        <table class="w-full text-left border-collapse my-6">
            <thead>
                <tr class="border-b border-white/10 text-text-primary">
                    <th class="py-2 px-4">Method</th>
                    <th class="py-2 px-4">Dice Coefficient</th>
                    <th class="py-2 px-4">Sensitivity</th>
                    <th class="py-2 px-4">False Positives / Scan</th>
                </tr>
            </thead>
            <tbody>
                <tr class="border-b border-white/5">
                    <td class="py-2 px-4"><code translate="no">U-Net</code></td>
                    <td class="py-2 px-4">0.89</td>
                    <td class="py-2 px-4">94.0%</td>
                    <td class="py-2 px-4">4.0</td>
                </tr>
                <tr class="border-b border-white/5">
                    <td class="py-2 px-4"
                        ><code translate="no">ResNet-50 FCN</code></td
                    >
                    <td class="py-2 px-4">0.90</td>
                    <td class="py-2 px-4">95.2%</td>
                    <td class="py-2 px-4">3.5</td>
                </tr>
                <tr class="bg-accent-primary/5">
                    <td class="py-2 px-4 font-semibold text-accent-primary"
                        ><code translate="no">Bayesian U-Net</code> (Ours)</td
                    >
                    <td class="py-2 px-4 font-semibold text-accent-primary"
                        >0.92</td
                    >
                    <td class="py-2 px-4 font-semibold text-accent-primary"
                        >96.5%</td
                    >
                    <td class="py-2 px-4 font-semibold text-accent-primary"
                        >1.2</td
                    >
                </tr>
            </tbody>
        </table>
    </div>

    <h2>Error Analysis & Failure Modes</h2>
    <ul>
        <li>
            <strong>Small Nodule Misses:</strong> Nodules &lt; 3mm are still challenging.
            50% of our false negatives came from nodules smaller than 4mm.
        </li>
        <li>
            <strong>Vascular Confusion:</strong> The model occasionally confuses cross-sections
            of blood vessels with nodules.
            <em>Mitigation:</em> Added a 3D context-aware post-processing step that
            checks continuity across adjacent Z-slices (vessels are continuous, nodules
            are localized).
        </li>
    </ul>

    <details open>
        <summary>Engineering Notes: Data Pipeline</summary>
        <p>
            Preprocessing 3D <code translate="no">DICOM</code> images is a bottleneck.
            I implemented a
            <code translate="no">DALI</code>-based GPU-accelerated preprocessing
            pipeline (resampling to 1mm isotropic spacing, normalization) which
            sped up training epoch time by 4x compared to CPU-based <code
                translate="no">NumPy</code
            > preprocessing.
        </p>
    </details>

    <h2>What I'd Do Next</h2>
    <ul>
        <li>
            Explore 3D <code translate="no">U-Net</code> architectures (<code
                translate="no">V-Net</code
            >) for better volumetric context.
        </li>
        <li>
            Implement Active Learning loop to query radiologists only for
            high-uncertainty samples.
        </li>
    </ul>
</ProjectDetailLayout>
